{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "09557025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x721f105d44f0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e53cb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.model import GPT2, PretrainedName\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model, _pretrained_model = GPT2.from_pretrained(\n",
    "    PretrainedName.GPT2_SMALL, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "06834762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "['Adam', 'Adams', 'Albert', 'Alexander', 'Ali', 'Allen', 'Anderson', 'Andrew', 'Anthony', 'Arthur', 'Austin', 'Ball', 'Bear', 'Beck', 'Beer', 'Bell', 'Berry', 'Best', 'Bill', 'Bird', 'Black', 'Blake', 'Bloom', 'Bob', 'Bone', 'Brain', 'Bright', 'Brook', 'Brown', 'Bruce', 'Bull', 'Burn', 'Bush', 'Button', 'Carter', 'Chan', 'Chance', 'Charge', 'Charles', 'Child', 'Church', 'Clark', 'Close', 'Cole', 'Coll', 'Collins', 'Connor', 'Cook', 'Core', 'Court', 'Craig', 'Crew', 'Cross', 'Dallas', 'Daniel', 'David', 'Davis', 'Day', 'Dean', 'Diamond', 'Dick', 'Donald', 'Down', 'Driver', 'East', 'Edge', 'England', 'English', 'Fall', 'Field', 'Fish', 'Ford', 'Fox', 'Frame', 'France', 'French', 'Friend', 'Gall', 'Gene', 'George', 'Given', 'Glass', 'Gold', 'Good', 'Gordon', 'Graham', 'Grant', 'Gray', 'Green', 'Grey', 'Guest', 'Hall', 'Hamilton', 'Hand', 'Harris', 'Harry', 'Hart', 'Head', 'Henry', 'Hill', 'Hope', 'Houston', 'Howard', 'Hunt', 'Hunter', 'Ireland', 'Islam', 'Jackson', 'Jacob', 'James', 'Jerry', 'John', 'Johnson', 'Jones', 'Jordan', 'Joseph', 'Judge', 'Kay', 'Keith', 'Kelly', 'Kent', 'Keys', 'Kill', 'King', 'Kings', 'Knight', 'Kyle', 'Lake', 'Large', 'Last', 'Lee', 'Lewis', 'Lind', 'Line', 'Little', 'Lock', 'London', 'Long', 'Lord', 'Love', 'Luke', 'Mac', 'Main', 'Major', 'Marsh', 'Martin', 'May', 'Michael', 'Mill', 'Miller', 'Moon', 'Moore', 'More', 'Morgan', 'Murray', 'Neal', 'Norm', 'North', 'Number', 'Overall', 'Pack', 'Page', 'Park', 'Patrick', 'Paul', 'Peace', 'Penn', 'Phoenix', 'Pick', 'Pierre', 'Pitt', 'Pope', 'Power', 'Price', 'Prime', 'Prince', 'Prior', 'Rand', 'Raven', 'Read', 'Reader', 'Reading', 'Reilly', 'Render', 'Rich', 'Rick', 'Ring', 'Robert', 'Roberts', 'Robin', 'Roman', 'Rose', 'Ross', 'Rush', 'Russell', 'Rust', 'Ryan', 'Said', 'Salt', 'Sanders', 'Scott', 'Senior', 'Sharp', 'Short', 'Simon', 'Small', 'Smart', 'Smith', 'Snow', 'South', 'Southern', 'Speed', 'Stack', 'Staff', 'Steel', 'Stephen', 'Stock', 'Stone', 'Strange', 'Street', 'Strong', 'Sullivan', 'Tang', 'Taylor', 'Tell', 'Terry', 'Thom', 'Thomas', 'Thompson', 'Tips', 'Todd', 'Train', 'Trump', 'Tyler', 'Walker', 'Wall', 'Ward', 'Ware', 'Warren', 'Water', 'Were', 'West', 'Western', 'White', 'Wild', 'Will', 'Williams', 'Wilson', 'Winter', 'Wolf', 'Wood', 'Yang', 'York', 'Young']\n",
      "--------------------------------------------------------------------------------\n",
      "When Patrick and Brown went to the store, Anderson gave a drink to\n",
      "When Robin and Fish went to the store, Down gave a drink to\n",
      "When Day and Chan went to the store, Roberts gave a drink to\n",
      "When Bright and Price went to the store, Robin gave a drink to\n",
      "When Thompson and Love went to the store, Bloom gave a drink to\n",
      "When Moore and Jacob went to the store, Anthony gave a drink to\n",
      "When Andrew and Bob went to the store, David gave a drink to\n",
      "When Diamond and Last went to the store, Murray gave a drink to\n",
      "When Anderson and Major went to the store, Craig gave a drink to\n",
      "When Render and Penn went to the store, Read gave a drink to\n",
      "--------------------------------------------------------------------------------\n",
      "When Love and Jackson went to the store, Love gave a drink to\n",
      "When Davis and Jordan went to the store, Davis gave a drink to\n",
      "When Moon and Ford went to the store, Moon gave a drink to\n",
      "When Smith and Tang went to the store, Smith gave a drink to\n",
      "When Adams and Russell went to the store, Adams gave a drink to\n",
      "When Smart and Church went to the store, Smart gave a drink to\n",
      "When Raven and Jacob went to the store, Raven gave a drink to\n",
      "When Gray and Ford went to the store, Gray gave a drink to\n",
      "When Child and David went to the store, Child gave a drink to\n",
      "When Will and Rust went to the store, Will gave a drink to\n",
      "--------------------------------------------------------------------------------\n",
      "When Grant and Bright went to the store, Bright gave a drink to\n",
      "When Bob and Head went to the store, Head gave a drink to\n",
      "When Bone and Hall went to the store, Hall gave a drink to\n",
      "When Stock and Green went to the store, Green gave a drink to\n",
      "When Murray and English went to the store, English gave a drink to\n",
      "When Smart and Ball went to the store, Ball gave a drink to\n",
      "When Ring and Kay went to the store, Kay gave a drink to\n",
      "When Long and Burn went to the store, Burn gave a drink to\n",
      "When Wolf and Ward went to the store, Ward gave a drink to\n",
      "When Hart and Black went to the store, Black gave a drink to\n"
     ]
    }
   ],
   "source": [
    "from data.names_data_source import NamesDataSource\n",
    "from learning.gpt2.ioi_circuit_analyzer import NameSampler, PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "\n",
    "names_data_source = NamesDataSource.load(\n",
    "    data_folder=\"../datasets/names\",\n",
    ")\n",
    "\n",
    "# Get all English names\n",
    "all_english_names = names_data_source.country_idx_to_names[4]\n",
    "\n",
    "\n",
    "def filter_single_token_names(names: list[str]) -> list[str]:\n",
    "    all_indices = tokenizer.encode_batch(names)\n",
    "    single_token_indices = [indices for indices in all_indices if len(indices) == 1]\n",
    "    return tokenizer.decode_batch(single_token_indices)\n",
    "\n",
    "\n",
    "# Keep only the names that are single tokens (without space padding). E.g. \"John\"\n",
    "filtered_names = filter_single_token_names(all_english_names)\n",
    "\n",
    "# Add space padding to the names, and filter again\n",
    "padded_filtered_names = [\" \" + name for name in filtered_names]\n",
    "single_token_names = filter_single_token_names(padded_filtered_names)\n",
    "single_token_names = [name[1:] for name in single_token_names]\n",
    "\n",
    "# The final names are guaranteed to be single tokens, with or without space padding. E.g. \" John\" and \"John\"\n",
    "print(len(single_token_names))\n",
    "print(single_token_names)\n",
    "\n",
    "name_sampler = NameSampler(single_token_names)\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"When {s1} and {s2} went to the store, {s3} gave a drink to\",\n",
    "    name_sampler=name_sampler,\n",
    ")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "for _ in range(10):\n",
    "    print(prompt_template.sample_abc())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "for _ in range(10):\n",
    "    print(prompt_template.sample_aba())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "for _ in range(10):\n",
    "    print(prompt_template.sample_abb())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "96735655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.ioi_circuit_analyzer import IoiCircuitAnalyzer\n",
    "\n",
    "analyzer = IoiCircuitAnalyzer(model, tokenizer, prompt_template, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "069059d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC --------------------------------------------------------------------------------\n",
      "When Mac and French went to the store, Stack gave a drink to\n",
      "0.19  the\n",
      "0.10  them\n",
      "0.06  a\n",
      "When Pack and Number went to the store, Thom gave a drink to\n",
      "0.16  the\n",
      "0.08  a\n",
      "0.07  his\n",
      "When Strong and Hamilton went to the store, Michael gave a drink to\n",
      "0.16  the\n",
      "0.08  a\n",
      "0.07  them\n",
      "When Court and Reader went to the park, Best gave a leaf to\n",
      "0.30  the\n",
      "0.05  a\n",
      "0.04  Judge\n",
      "When Ball and Pierre went to the park, Dean gave a leaf to\n",
      "0.13  the\n",
      "0.07  Pierre\n",
      "0.06  them\n",
      "When Said and France went to the park, York gave a leaf to\n",
      "0.26  the\n",
      "0.06  his\n",
      "0.05  a\n",
      "Yesterday Black and Strange went to the store. Diamond gave a drink to\n",
      "0.20  the\n",
      "0.08  me\n",
      "0.08  them\n",
      "Yesterday Sullivan and Brain went to the store. Head gave a drink to\n",
      "0.16  the\n",
      "0.10  Sullivan\n",
      "0.09  them\n",
      "Yesterday Ford and Judge went to the store. Park gave a drink to\n",
      "0.22  the\n",
      "0.13  them\n",
      "0.09  Judge\n",
      "ABA --------------------------------------------------------------------------------\n",
      "When Staff and Hand went to the store, Staff gave a drink to\n",
      "0.36  Hand\n",
      "0.16  the\n",
      "0.06  a\n",
      "When Clark and Harris went to the store, Clark gave a drink to\n",
      "0.51  Harris\n",
      "0.12  the\n",
      "0.05  a\n",
      "When Guest and Dallas went to the store, Guest gave a drink to\n",
      "0.29  Dallas\n",
      "0.21  the\n",
      "0.06  a\n",
      "When Pope and Fall went to the park, Pope gave a leaf to\n",
      "0.29  the\n",
      "0.06  a\n",
      "0.04  his\n",
      "When Read and Water went to the park, Read gave a leaf to\n",
      "0.22  the\n",
      "0.12  a\n",
      "0.03  his\n",
      "When Prime and Peace went to the park, Prime gave a leaf to\n",
      "0.27  the\n",
      "0.06  a\n",
      "0.05  his\n",
      "Yesterday Bill and Neal went to the store. Bill gave a drink to\n",
      "0.42  Neal\n",
      "0.12  the\n",
      "0.07  a\n",
      "Yesterday Park and Cole went to the store. Park gave a drink to\n",
      "0.60  Cole\n",
      "0.08  the\n",
      "0.05  a\n",
      "Yesterday London and Ring went to the store. London gave a drink to\n",
      "0.16  the\n",
      "0.09  them\n",
      "0.08  me\n",
      "ABB --------------------------------------------------------------------------------\n",
      "When Down and Clark went to the store, Clark gave a drink to\n",
      "0.17  the\n",
      "0.11  Clark\n",
      "0.10  a\n",
      "When Keith and Head went to the store, Head gave a drink to\n",
      "0.54  Keith\n",
      "0.08  the\n",
      "0.04  them\n",
      "When Field and Young went to the store, Young gave a drink to\n",
      "0.19  Field\n",
      "0.15  the\n",
      "0.07  Young\n",
      "When Ward and Patrick went to the park, Patrick gave a leaf to\n",
      "0.30  Ward\n",
      "0.12  the\n",
      "0.05  a\n",
      "When Prior and Main went to the park, Main gave a leaf to\n",
      "0.17  the\n",
      "0.06  a\n",
      "0.03  his\n",
      "When Davis and Prince went to the park, Prince gave a leaf to\n",
      "0.48  Davis\n",
      "0.13  the\n",
      "0.04  a\n",
      "Yesterday Good and Stephen went to the store. Stephen gave a drink to\n",
      "0.18  the\n",
      "0.12  me\n",
      "0.09  Stephen\n",
      "Yesterday Ryan and Salt went to the store. Salt gave a drink to\n",
      "0.53  Ryan\n",
      "0.10  the\n",
      "0.03  them\n",
      "Yesterday Beer and Dean went to the store. Dean gave a drink to\n",
      "0.17  the\n",
      "0.09  Dean\n",
      "0.06  them\n"
     ]
    }
   ],
   "source": [
    "def run_case(analyzer: IoiCircuitAnalyzer, model: GPT2, case: str, k: int):\n",
    "    print(case)\n",
    "    result = analyzer.topk_probs(case, k)\n",
    "    for i in range(k):\n",
    "        indices = [int(result.top_indices[i])]\n",
    "        print(f\"{result.top_probs[i]:.2f} {tokenizer.decode(indices)}\")\n",
    "\n",
    "\n",
    "def run_test(analyzer: IoiCircuitAnalyzer, model: GPT2):\n",
    "    k = 3\n",
    "    templates: list[PromptTemplate] = [\n",
    "        PromptTemplate(\n",
    "            template=\"When {s1} and {s2} went to the store, {s3} gave a drink to\",\n",
    "            name_sampler=name_sampler,\n",
    "        ),\n",
    "        PromptTemplate(\n",
    "            template=\"When {s1} and {s2} went to the park, {s3} gave a leaf to\",\n",
    "            name_sampler=name_sampler,\n",
    "        ),\n",
    "        PromptTemplate(\n",
    "            template=\"Yesterday {s1} and {s2} went to the store. {s3} gave a drink to\",\n",
    "            name_sampler=name_sampler,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    print(\"ABC \" + \"-\" * 80)\n",
    "    for template in templates:\n",
    "        for _ in range(3):\n",
    "            run_case(analyzer, model, template.sample_abc(), k)\n",
    "\n",
    "    print(\"ABA \" + \"-\" * 80)\n",
    "    for template in templates:\n",
    "        for _ in range(3):\n",
    "            run_case(analyzer, model, template.sample_aba(), k)\n",
    "\n",
    "    print(\"ABB \" + \"-\" * 80)\n",
    "    for template in templates:\n",
    "        for _ in range(3):\n",
    "            run_case(analyzer, model, template.sample_abb(), k)\n",
    "\n",
    "\n",
    "run_test(analyzer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b44074c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(embedding_size=768, num_heads=12, num_blocks=12, vocab_size=50257, sequence_length=1024, feed_forward_expansion_factor=4, dropout=0.1, device=device(type='cuda'))\n",
      "GPT2(\n",
      "  (embedding): Embedding(50257, 768)\n",
      "  (positional_embedding): Embedding(1024, 768)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (blocks_module): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attention): MultiHeadAttention(\n",
      "        (heads_module): ModuleList(\n",
      "          (0-11): 12 x AttentionHead(\n",
      "            (query): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (gelu): GELU(approximate='tanh')\n",
      "        (projection): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (linear): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.config)\n",
    "print(model)\n",
    "\n",
    "# Phase A: baseline forward pass.\n",
    "# All heads are frozen to the baseline computations\n",
    "batch_size = 2**7\n",
    "analyzer.capture_baseline_output(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "368cfc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Mary and John went to the store, John gave a drink to\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Most impactful heads (by KL divergence)\n",
      "================================================================================\n",
      "#1 \tHead [11][10] \tKL: 0.1395\tTV: 0.2426\tL2: 0.2691\tMary prob: -0.2424\tJohn prob: 0.0054\tLogit diff: -0.5275\t\n",
      "#2 \tHead [11][1] \tKL: 0.0753\tTV: 0.1808\tL2: 0.1767\tMary prob: 0.1469\tJohn prob: 0.0324\tLogit diff: -0.3763\t\n",
      "#3 \tHead [11][2] \tKL: 0.0360\tTV: 0.1259\tL2: 0.1393\tMary prob: 0.1255\tJohn prob: -0.0022\tLogit diff: 0.3666\t\n",
      "#4 \tHead [11][3] \tKL: 0.0185\tTV: 0.0921\tL2: 0.0999\tMary prob: 0.0895\tJohn prob: -0.0087\tLogit diff: 0.3589\t\n",
      "#5 \tHead [11][6] \tKL: 0.0062\tTV: 0.0533\tL2: 0.0588\tMary prob: 0.0530\tJohn prob: -0.0028\tLogit diff: 0.1713\t\n",
      "#6 \tHead [11][8] \tKL: 0.0046\tTV: 0.0326\tL2: 0.0243\tMary prob: -0.0149\tJohn prob: 0.0057\tLogit diff: -0.1336\t\n",
      "#7 \tHead [11][11] \tKL: 0.0032\tTV: 0.0388\tL2: 0.0398\tMary prob: 0.0348\tJohn prob: 0.0033\tLogit diff: 0.0242\t\n",
      "#8 \tHead [11][0] \tKL: 0.0008\tTV: 0.0160\tL2: 0.0122\tMary prob: -0.0084\tJohn prob: -0.0030\tLogit diff: 0.0299\t\n",
      "#9 \tHead [11][9] \tKL: 0.0006\tTV: 0.0164\tL2: 0.0171\tMary prob: 0.0154\tJohn prob: -0.0001\tLogit diff: 0.0368\t\n",
      "#10 \tHead [11][7] \tKL: 0.0005\tTV: 0.0144\tL2: 0.0151\tMary prob: -0.0138\tJohn prob: 0.0001\tLogit diff: -0.0329\t\n",
      "#11 \tHead [11][5] \tKL: 0.0002\tTV: 0.0067\tL2: 0.0045\tMary prob: -0.0025\tJohn prob: 0.0027\tLogit diff: -0.0516\t\n",
      "#12 \tHead [11][4] \tKL: 0.0001\tTV: 0.0049\tL2: 0.0037\tMary prob: -0.0034\tJohn prob: 0.0002\tLogit diff: -0.0114\t\n"
     ]
    }
   ],
   "source": [
    "from learning.gpt2.ioi_circuit_analyzer import HeadAnalysisResult\n",
    "\n",
    "\n",
    "results = []\n",
    "for head_idx in range(model.config.num_heads):\n",
    "    result: HeadAnalysisResult = analyzer.analyze_head(\n",
    "        11, head_idx, \"Mary\", \"John\", \"John\"\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "print(prompt_template.from_abb(\"Mary\", \"John\"))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY: Most impactful heads (by KL divergence)\")\n",
    "print(\"=\" * 80)\n",
    "sorted_results = sorted(\n",
    "    enumerate(results), key=lambda x: x[1].kl_divergence, reverse=True\n",
    ")\n",
    "for i, (head_idx, result) in enumerate(sorted_results):\n",
    "    print(\n",
    "        f\"#{i + 1} \\tHead [11][{head_idx}] \\t\"\n",
    "        f\"KL: {result.kl_divergence:.4f}\\t\"\n",
    "        f\"TV: {result.total_variation:.4f}\\t\"\n",
    "        f\"L2: {result.l2_distance:.4f}\\t\"\n",
    "        f\"Mary prob: {result.s1_prob_change:.4f}\\t\"\n",
    "        f\"John prob: {result.s2_prob_change:.4f}\\t\"\n",
    "        f\"Logit diff: {result.logit_diff_change:.4f}\\t\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
