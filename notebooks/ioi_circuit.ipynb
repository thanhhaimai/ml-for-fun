{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09557025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d344acf15f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53cb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.model import GPT2, PretrainedName\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model, _pretrained_model = GPT2.from_pretrained(\n",
    "    PretrainedName.GPT2_SMALL, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96735655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.ioi_circuit_analyzer import IoiCircuitAnalyzer\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "analyzer = IoiCircuitAnalyzer(model, tokenizer, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06834762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adam', 'Adams', 'Albert', 'Alexander', 'Ali', 'Allen', 'Anderson', 'Andrew', 'Anthony', 'Arthur', 'Austin', 'Ball', 'Bear', 'Beck', 'Beer', 'Bell', 'Berry', 'Best', 'Bill', 'Bird', 'Black', 'Blake', 'Bloom', 'Bob', 'Bone', 'Brain', 'Bright', 'Brook', 'Brown', 'Bruce', 'Bull', 'Burn', 'Bush', 'Button', 'Carter', 'Chan', 'Chance', 'Charge', 'Charles', 'Child', 'Church', 'Clark', 'Close', 'Cole', 'Coll', 'Collins', 'Connell', 'Connor', 'Cook', 'Core', 'Court', 'Craig', 'Crew', 'Cross', 'Dallas', 'Daniel', 'David', 'Davis', 'Day', 'Dean', 'Diamond', 'Dick', 'Donald', 'Down', 'Driver', 'East', 'Edge', 'England', 'English', 'Fall', 'Field', 'Fish', 'Ford', 'Fox', 'Frame', 'France', 'French', 'Friend', 'Gall', 'Gene', 'George', 'Given', 'Glass', 'Gold', 'Good', 'Gordon', 'Graham', 'Grant', 'Gray', 'Green', 'Grey', 'Guest', 'Hall', 'Hamilton', 'Hand', 'Harris', 'Harry', 'Hart', 'Head', 'Henry', 'Hill', 'Hope', 'Houston', 'Howard', 'Hunt', 'Hunter', 'Ireland', 'Islam', 'Jackson', 'Jacob', 'James', 'Jerry', 'John', 'Johnson', 'Jones', 'Jordan', 'Joseph', 'Judge', 'Kay', 'Keefe', 'Keith', 'Kelly', 'Kent', 'Keys', 'Kill', 'King', 'Kings', 'Knight', 'Kyle', 'Lake', 'Large', 'Last', 'Leary', 'Lee', 'Lewis', 'Lind', 'Line', 'Little', 'Lock', 'London', 'Long', 'Lord', 'Love', 'Luke', 'Mac', 'Main', 'Major', 'Malley', 'Marsh', 'Martin', 'May', 'Michael', 'Mill', 'Miller', 'Moon', 'Moore', 'More', 'Morgan', 'Murray', 'Neal', 'Neill', 'Norm', 'North', 'Number', 'Overall', 'Pack', 'Page', 'Park', 'Patrick', 'Paul', 'Peace', 'Penn', 'Phoenix', 'Pick', 'Pierre', 'Pitt', 'Pope', 'Power', 'Price', 'Prime', 'Prince', 'Prior', 'Rand', 'Raven', 'Read', 'Reader', 'Reading', 'Reilly', 'Render', 'Rich', 'Rick', 'Ring', 'Robert', 'Roberts', 'Robin', 'Roman', 'Rose', 'Ross', 'Rush', 'Russell', 'Rust', 'Ryan', 'Said', 'Salt', 'Sanders', 'Scott', 'Senior', 'Sharp', 'Short', 'Simon', 'Small', 'Smart', 'Smith', 'Snow', 'South', 'Southern', 'Speed', 'Stack', 'Staff', 'Steel', 'Stephen', 'Stock', 'Stone', 'Strange', 'Street', 'Strong', 'Sullivan', 'Tang', 'Taylor', 'Tell', 'Terry', 'Thom', 'Thomas', 'Thompson', 'Tips', 'Todd', 'Train', 'Trump', 'Tyler', 'Walker', 'Wall', 'Ward', 'Ware', 'Warren', 'Water', 'Were', 'West', 'Western', 'White', 'Wild', 'Will', 'Williams', 'Wilson', 'Winter', 'Wolf', 'Wood', 'Yang', 'York', 'Young']\n"
     ]
    }
   ],
   "source": [
    "from data.names_data_source import NamesDataSource\n",
    "\n",
    "\n",
    "names_data_source = NamesDataSource.load(\n",
    "    data_folder=\"../datasets/names\",\n",
    ")\n",
    "\n",
    "all_english_names = names_data_source.country_idx_to_names[4]\n",
    "all_indices = tokenizer.encode_batch(all_english_names)\n",
    "single_token_indices = [indices for indices in all_indices if len(indices) == 1]\n",
    "single_token_names = tokenizer.decode_batch(single_token_indices)\n",
    "print(single_token_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069059d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Vincent and Vanessa went to the park, Vincent gave a leaf to\n",
      "0.51  Vanessa\n",
      "0.12  the\n",
      "0.05  a\n",
      "When Vincent and Vanessa went to the park, Vanessa gave a leaf to\n",
      "0.54  Vincent\n",
      "0.09  the\n",
      "0.03  her\n",
      "Mary and John went to the store. John gave a drink to\n",
      "0.31  them\n",
      "0.15  John\n",
      "0.13  the\n",
      "Mary and John went to the store; John gave a drink to\n",
      "0.33  them\n",
      "0.15  John\n",
      "0.14  the\n",
      "Mary and John went to the store! John gave a drink to\n",
      "0.27  them\n",
      "0.13  the\n",
      "0.10  John\n",
      "Mary and John went to the store. Mary gave a drink to\n",
      "0.46  John\n",
      "0.14  them\n",
      "0.11  the\n",
      "Mary and John went to the store; Mary gave a drink to\n",
      "0.29  John\n",
      "0.21  them\n",
      "0.13  the\n",
      "Mary and John went to the store! Mary gave a drink to\n",
      "0.40  John\n",
      "0.14  the\n",
      "0.12  them\n"
     ]
    }
   ],
   "source": [
    "def run_case(analyzer: IoiCircuitAnalyzer, model: GPT2, case: str, k: int):\n",
    "    print(case)\n",
    "    result = analyzer.topk_logits(case, k)\n",
    "    for i in range(k):\n",
    "        indices = [int(result.top_indices[i])]\n",
    "        print(f\"{result.top_probs[i]:.2f} {tokenizer.decode(indices)}\")\n",
    "\n",
    "\n",
    "def run_test(analyzer: IoiCircuitAnalyzer, model: GPT2):\n",
    "    k = 3\n",
    "    # From the paper: https://arxiv.org/abs/2211.00593\n",
    "    cases = [\n",
    "        \"When Mary and John went to the store, John gave a drink to\",\n",
    "        \"When Vincent and Vanessa went to the park, Vincent gave a leaf to\",\n",
    "        \"When Vincent and Vanessa went to the park, Vanessa gave a leaf to\",\n",
    "        \"Mary and John went to the store. John gave a drink to\",\n",
    "        \"Mary and John went to the store; John gave a drink to\",\n",
    "        \"Mary and John went to the store! John gave a drink to\",\n",
    "        \"Mary and John went to the store. Mary gave a drink to\",\n",
    "        \"Mary and John went to the store; Mary gave a drink to\",\n",
    "        \"Mary and John went to the store! Mary gave a drink to\",\n",
    "    ]\n",
    "\n",
    "    for case in cases:\n",
    "        run_case(analyzer, model, case, k)\n",
    "\n",
    "\n",
    "print(\"-\" * 80)\n",
    "run_test(analyzer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b44074c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2(\n",
      "  (embedding): Embedding(50257, 768)\n",
      "  (positional_embedding): Embedding(1024, 768)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (blocks_module): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attention): MultiHeadAttention(\n",
      "        (heads_module): ModuleList(\n",
      "          (0-11): 12 x AttentionHead(\n",
      "            (query): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=64, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (gelu): GELU(approximate='tanh')\n",
      "        (projection): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (linear): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][0]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.46  Mary\n",
      "0.20  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][1]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.31  them\n",
      "0.30  Mary\n",
      "0.10  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][2]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.38  Mary\n",
      "0.24  them\n",
      "0.08  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][3]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.38  Mary\n",
      "0.24  them\n",
      "0.08  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][4]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.44  Mary\n",
      "0.22  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][5]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.44  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][6]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.38  Mary\n",
      "0.24  them\n",
      "0.08  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][7]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.47  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][8]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.46  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][9]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.44  Mary\n",
      "0.22  them\n",
      "0.07  the\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][10]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.65  Mary\n",
      "0.12  them\n",
      "0.06  John\n",
      "--------------------------------------------------------------------------------\n",
      "Testing head [11][11]\n",
      "When Mike and Tom went to the store, Rise gave a drink to\n",
      "0.13  them\n",
      "0.12  the\n",
      "0.09  Tom\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.45  Mary\n",
      "0.21  them\n",
      "0.07  the\n",
      "When Mary and John went to the store, John gave a drink to\n",
      "0.41  Mary\n",
      "0.23  them\n",
      "0.08  the\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "\n",
    "def test_head(analyzer: IoiCircuitAnalyzer, model: GPT2, block_idx, head_idx):\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Testing head [{block_idx}][{head_idx}]\")\n",
    "\n",
    "    # A: x_new forward pass.\n",
    "    # All heads are frozen to the x_new computations\n",
    "    model.set_capture_output(True)\n",
    "    model.set_use_frozen_output(False)\n",
    "    run_case(\n",
    "        analyzer, model, \"When Mike and Tom went to the store, Rise gave a drink to\", 3\n",
    "    )\n",
    "    captured_output = model.blocks[block_idx].attention.heads[head_idx].frozen_output\n",
    "\n",
    "    # B: x_ori forward pass.\n",
    "    # All heads are frozen to the x_ori computations\n",
    "    model.set_capture_output(True)\n",
    "    model.set_use_frozen_output(False)\n",
    "    run_case(\n",
    "        analyzer, model, \"When Mary and John went to the store, John gave a drink to\", 3\n",
    "    )\n",
    "\n",
    "    # C: x_ori forward pass with `h` (head `head_idx` of block `block_idx`) patched from A\n",
    "    # All heads except `h` are frozen to the x_ori computations\n",
    "    # `h` is frozen to the x_new computations\n",
    "    model.set_capture_output(False)\n",
    "    model.set_use_frozen_output(True)\n",
    "    model.blocks[block_idx].attention.heads[head_idx].frozen_output = captured_output\n",
    "    run_case(\n",
    "        analyzer, model, \"When Mary and John went to the store, John gave a drink to\", 3\n",
    "    )\n",
    "\n",
    "\n",
    "for head_idx in range(model.config.num_heads):\n",
    "    test_head(analyzer, model, 11, head_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
