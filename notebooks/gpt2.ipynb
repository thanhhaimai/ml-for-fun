{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09557025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x773c001b0550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac37b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.model import ModelConfig, LearnerConfig\n",
    "\n",
    "\n",
    "config = ModelConfig(\n",
    "    sequence_length=2**9,\n",
    "    embedding_size=2**8,\n",
    "    num_heads=2**3,\n",
    "    num_blocks=2**2,\n",
    "    dropout=0.1,\n",
    "    device=torch.device(\"cuda\"),\n",
    ")\n",
    "\n",
    "learner_config = LearnerConfig(\n",
    "    batch_size=2**8,\n",
    "    epochs=10,\n",
    "    learning_rate=1e-3,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53cb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.gpt2.model import GPT2, PretrainedName\n",
    "\n",
    "\n",
    "model = GPT2.from_pretrained(PretrainedName.GPT2_SMALL, device=torch.device(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96735655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm studying machine learning and do one of my classes at a stony-dobberga. GET MORE CRYPTO STORIES.\n",
      "\n",
      "BUT the problem isn't internet abstractions. It's huge pulls and events that slither from one level to the next .\n",
      "\n",
      "\"Reports contain knowledge that has all sorts and forms of causality and content with how people collaboratively structure 'news', organize or disseminate it's content as well as the context in which it originated,\" Kuhn told me. He\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "indices = tokenizer.encode(\"Hi, I'm studying machine learning\")\n",
    "inputs = torch.tensor([indices], dtype=torch.long, device=config.device)\n",
    "outputs = model.generate(inputs, 100)\n",
    "\n",
    "# NOTE: geesus GPT2 language has so many NSFW words\n",
    "for i in range(outputs.shape[0]):\n",
    "    print(tokenizer.decode(outputs[i].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
