{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09557025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x71b9d83c4210>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88ccafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.shakespeare_data_source import ShakespeareDataSource\n",
    "from data.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "shakespeare_data_source = ShakespeareDataSource.load(\n",
    "    file_path=\"../datasets/shakespeare/input.txt\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac37b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.shakespeare_generator.model import Config\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    batch_size=2**8,\n",
    "    sequence_length=2**9,\n",
    "    embedding_size=2**8,\n",
    "    num_heads=2**3,\n",
    "    num_blocks=2**2,\n",
    "    epochs=10,\n",
    "    dropout=0.1,\n",
    "    learning_rate=1e-3,\n",
    "    patience=30,\n",
    "    min_delta=1e-3,\n",
    "    device=torch.device(\"cuda\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfe39551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample(input=tensor([19, 48, 57, 58, 59,  2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 15, 44, 45,\n",
      "        54, 57, 44,  2, 62, 44,  2, 55, 57, 54, 42, 44, 44, 43,  2, 40, 53, 64,\n",
      "         2, 45, 60, 57, 59, 47, 44, 57,  7,  2, 47, 44, 40, 57,  2, 52, 44,  2,\n",
      "        58, 55, 44, 40, 50,  9,  1,  1, 14, 51, 51, 11,  1, 32, 55, 44, 40, 50,\n",
      "         7,  2, 58, 55, 44, 40, 50,  9,  1,  1, 19, 48, 57, 58, 59,  2, 16, 48,\n",
      "        59, 48, 65, 44, 53, 11,  1, 38, 54, 60,  2, 40, 57, 44,  2, 40, 51, 51,\n",
      "         2, 57, 44, 58, 54, 51, 61, 44, 43,  2, 57, 40, 59, 47, 44, 57,  2, 59,\n",
      "        54,  2, 43, 48, 44,  2, 59, 47, 40, 53,  2, 59, 54,  2, 45, 40, 52, 48,\n",
      "        58, 47, 13,  1,  1, 14, 51, 51, 11,  1, 31, 44, 58, 54, 51, 61, 44, 43,\n",
      "         9,  2, 57, 44, 58, 54, 51, 61, 44, 43,  9,  1,  1, 19, 48, 57, 58, 59,\n",
      "         2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 19, 48, 57, 58, 59,  7,  2, 64,\n",
      "        54, 60,  2, 50, 53, 54, 62,  2, 16, 40, 48, 60, 58,  2, 26, 40, 57, 42,\n",
      "        48, 60, 58,  2, 48, 58,  2, 42, 47, 48, 44, 45,  2, 44, 53, 44, 52, 64,\n",
      "         2, 59, 54,  2, 59, 47, 44,  2, 55, 44, 54, 55, 51, 44,  9,  1,  1, 14,\n",
      "        51, 51, 11,  1, 36, 44,  2, 50, 53, 54, 62,  6, 59,  7,  2, 62, 44,  2,\n",
      "        50, 53, 54, 62,  6, 59,  9,  1,  1, 19, 48, 57, 58, 59,  2, 16, 48, 59,\n",
      "        48, 65, 44, 53, 11,  1, 25, 44, 59,  2, 60, 58,  2, 50, 48, 51, 51,  2,\n",
      "        47, 48, 52,  7,  2, 40, 53, 43,  2, 62, 44,  6, 51, 51,  2, 47, 40, 61,\n",
      "        44,  2, 42, 54, 57, 53,  2, 40, 59,  2, 54, 60, 57,  2, 54, 62, 53,  2,\n",
      "        55, 57, 48, 42, 44,  9,  1, 22, 58,  6, 59,  2, 40,  2, 61, 44, 57, 43,\n",
      "        48, 42, 59, 13,  1,  1, 14, 51, 51, 11,  1, 27, 54,  2, 52, 54, 57, 44,\n",
      "         2, 59, 40, 51, 50, 48, 53, 46,  2, 54, 53,  6, 59, 12,  2, 51, 44, 59,\n",
      "         2, 48, 59,  2, 41, 44,  2, 43, 54, 53, 44, 11,  2, 40, 62, 40, 64,  7,\n",
      "         2, 40, 62, 40, 64,  3,  1,  1, 32, 44, 42, 54, 53, 43,  2, 16, 48, 59,\n",
      "        48, 65, 44, 53, 11,  1, 28, 53, 44,  2, 62, 54, 57, 43,  7,  2, 46, 54,\n",
      "        54, 43,  2, 42, 48, 59, 48, 65, 44, 53, 58,  9,  1,  1, 19, 48, 57, 58,\n",
      "        59,  2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 36, 44,  2, 40, 57, 44,  2,\n",
      "        40, 42, 42, 54, 60, 53, 59, 44, 43,  2, 55, 54, 54, 57,  2, 42, 48, 59,\n",
      "        48, 65, 44, 53, 58,  7,  2, 59]), label=tensor([48, 57, 58, 59,  2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 15, 44, 45, 54,\n",
      "        57, 44,  2, 62, 44,  2, 55, 57, 54, 42, 44, 44, 43,  2, 40, 53, 64,  2,\n",
      "        45, 60, 57, 59, 47, 44, 57,  7,  2, 47, 44, 40, 57,  2, 52, 44,  2, 58,\n",
      "        55, 44, 40, 50,  9,  1,  1, 14, 51, 51, 11,  1, 32, 55, 44, 40, 50,  7,\n",
      "         2, 58, 55, 44, 40, 50,  9,  1,  1, 19, 48, 57, 58, 59,  2, 16, 48, 59,\n",
      "        48, 65, 44, 53, 11,  1, 38, 54, 60,  2, 40, 57, 44,  2, 40, 51, 51,  2,\n",
      "        57, 44, 58, 54, 51, 61, 44, 43,  2, 57, 40, 59, 47, 44, 57,  2, 59, 54,\n",
      "         2, 43, 48, 44,  2, 59, 47, 40, 53,  2, 59, 54,  2, 45, 40, 52, 48, 58,\n",
      "        47, 13,  1,  1, 14, 51, 51, 11,  1, 31, 44, 58, 54, 51, 61, 44, 43,  9,\n",
      "         2, 57, 44, 58, 54, 51, 61, 44, 43,  9,  1,  1, 19, 48, 57, 58, 59,  2,\n",
      "        16, 48, 59, 48, 65, 44, 53, 11,  1, 19, 48, 57, 58, 59,  7,  2, 64, 54,\n",
      "        60,  2, 50, 53, 54, 62,  2, 16, 40, 48, 60, 58,  2, 26, 40, 57, 42, 48,\n",
      "        60, 58,  2, 48, 58,  2, 42, 47, 48, 44, 45,  2, 44, 53, 44, 52, 64,  2,\n",
      "        59, 54,  2, 59, 47, 44,  2, 55, 44, 54, 55, 51, 44,  9,  1,  1, 14, 51,\n",
      "        51, 11,  1, 36, 44,  2, 50, 53, 54, 62,  6, 59,  7,  2, 62, 44,  2, 50,\n",
      "        53, 54, 62,  6, 59,  9,  1,  1, 19, 48, 57, 58, 59,  2, 16, 48, 59, 48,\n",
      "        65, 44, 53, 11,  1, 25, 44, 59,  2, 60, 58,  2, 50, 48, 51, 51,  2, 47,\n",
      "        48, 52,  7,  2, 40, 53, 43,  2, 62, 44,  6, 51, 51,  2, 47, 40, 61, 44,\n",
      "         2, 42, 54, 57, 53,  2, 40, 59,  2, 54, 60, 57,  2, 54, 62, 53,  2, 55,\n",
      "        57, 48, 42, 44,  9,  1, 22, 58,  6, 59,  2, 40,  2, 61, 44, 57, 43, 48,\n",
      "        42, 59, 13,  1,  1, 14, 51, 51, 11,  1, 27, 54,  2, 52, 54, 57, 44,  2,\n",
      "        59, 40, 51, 50, 48, 53, 46,  2, 54, 53,  6, 59, 12,  2, 51, 44, 59,  2,\n",
      "        48, 59,  2, 41, 44,  2, 43, 54, 53, 44, 11,  2, 40, 62, 40, 64,  7,  2,\n",
      "        40, 62, 40, 64,  3,  1,  1, 32, 44, 42, 54, 53, 43,  2, 16, 48, 59, 48,\n",
      "        65, 44, 53, 11,  1, 28, 53, 44,  2, 62, 54, 57, 43,  7,  2, 46, 54, 54,\n",
      "        43,  2, 42, 48, 59, 48, 65, 44, 53, 58,  9,  1,  1, 19, 48, 57, 58, 59,\n",
      "         2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 36, 44,  2, 40, 57, 44,  2, 40,\n",
      "        42, 42, 54, 60, 53, 59, 44, 43,  2, 55, 54, 54, 57,  2, 42, 48, 59, 48,\n",
      "        65, 44, 53, 58,  7,  2, 59, 47]))\n"
     ]
    }
   ],
   "source": [
    "from learning.shakespeare_generator.shakespeare_dataset import ShakespeareDataset\n",
    "\n",
    "shakespeare_dataset = ShakespeareDataset(\n",
    "    shakespeare_data_source=shakespeare_data_source,\n",
    "    tokenizer=tokenizer,\n",
    "    sequence_length=config.sequence_length,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "print(shakespeare_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6f7ba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Predict from empty input:\n",
      "\n",
      "CBTRWoawb!I'tzGxYpJlWDn,,?R.wJkQoNvhrBaLHvHSOoXnqfuQoOv?TskI-VFHbnDx:'MJdcLuIQc!!keWGl$mMDBEh&vLorHa\n",
      "\n",
      ";sJf\n",
      "Mnen-edDZ,sHu\n",
      "X?T?skMSrb iQsavxaPCFTp.M&:dXRtaKtKwkuL-$Kmdj,<|pad|>ah<|pad|>xB;.vw,3:xIvRZOvZLc.!jvETo;Yr\n",
      ";\n",
      "---------- Predict from first sample:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, t$go-Z$lTZoOG-<|pad|>tqaYzNEEforGEsal3bSJ:i,G\n",
      "BLdiMo<|pad|>ERU3v,N&&vtNnDgubd'G3ovp$bovEy'CYfpYC,uy<|pad|>d;Wwlq'EwiQ&:\n"
     ]
    }
   ],
   "source": [
    "from learning.shakespeare_generator.model import ShakespeareGenerator\n",
    "\n",
    "\n",
    "test_model = ShakespeareGenerator(\n",
    "    config=config,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "\n",
    "# shape: [2, 1] -- (B=2, S=1)\n",
    "inputs = torch.ones((2, 1), dtype=torch.long, device=config.device)\n",
    "outputs = test_model.generate(\n",
    "    inputs,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "print(\"---------- Predict from empty input:\")\n",
    "for i in range(outputs.shape[0]):\n",
    "    print(tokenizer.i2t(outputs[i].tolist()))\n",
    "\n",
    "# shape: [1, S]\n",
    "inputs = shakespeare_dataset[0].input.unsqueeze(0).to(config.device, non_blocking=True)\n",
    "outputs = test_model.generate(\n",
    "    inputs,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "print(\"---------- Predict from first sample:\")\n",
    "for i in range(outputs.shape[0]):\n",
    "    print(tokenizer.i2t(outputs[i].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73e15fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891906 111488 111488\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    shakespeare_dataset,\n",
    "    [0.8, 0.1, 0.1],\n",
    ")\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b022eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(batch_size=256, sequence_length=512, embedding_size=256, num_heads=8, num_blocks=4, epochs=10, dropout=0.1, learning_rate=0.001, patience=30, min_delta=0.001, device=device(type='cuda'))\n",
      "ParallelBatchLearner\n",
      "model=ShakespeareGenerator(\n",
      "  (embedding): Embedding(66, 256)\n",
      "  (positional_embedding): Embedding(512, 256)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=256, out_features=66, bias=True)\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ShakespeareGenerator                     --\n",
      "├─Embedding: 1-1                         16,896\n",
      "├─Embedding: 1-2                         131,072\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Block: 2-1                        --\n",
      "│    │    └─LayerNorm: 3-1               512\n",
      "│    │    └─MultiHeadAttention: 3-2      263,168\n",
      "│    │    └─LayerNorm: 3-3               512\n",
      "│    │    └─FeedForward: 3-4             262,912\n",
      "│    └─Block: 2-2                        --\n",
      "│    │    └─LayerNorm: 3-5               512\n",
      "│    │    └─MultiHeadAttention: 3-6      263,168\n",
      "│    │    └─LayerNorm: 3-7               512\n",
      "│    │    └─FeedForward: 3-8             262,912\n",
      "│    └─Block: 2-3                        --\n",
      "│    │    └─LayerNorm: 3-9               512\n",
      "│    │    └─MultiHeadAttention: 3-10     263,168\n",
      "│    │    └─LayerNorm: 3-11              512\n",
      "│    │    └─FeedForward: 3-12            262,912\n",
      "│    └─Block: 2-4                        --\n",
      "│    │    └─LayerNorm: 3-13              512\n",
      "│    │    └─MultiHeadAttention: 3-14     263,168\n",
      "│    │    └─LayerNorm: 3-15              512\n",
      "│    │    └─FeedForward: 3-16            262,912\n",
      "│    └─LayerNorm: 2-5                    512\n",
      "├─Linear: 1-4                            16,962\n",
      "=================================================================\n",
      "Total params: 2,273,858\n",
      "Trainable params: 2,273,858\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "optimizer=Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "criterion=CrossEntropyLoss()\n",
      "Starting training...\n",
      "Expecting initial loss around 4.189654742026425\n",
      "0/10 -- 2897.45s \tTrain loss \t1.4127 \tEval loss \t1.0745 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "He should not be so, too welcome how those.\n",
      "\n",
      "RICHARD:\n",
      "The honourable and here loves,\n",
      "That follows louring into decoil.\n",
      "\n",
      "EDWARD:\n",
      "Clare, who are dear but that in robs?\n",
      "\n",
      "EDWARD:\n",
      "Now, ow, consentable apes shall.\n",
      "\n",
      "WARWICK:\n",
      "Where should never long his bodies love?\n",
      "\n",
      "RICHARD:\n",
      "His grace, his drum son at his to brow,\n",
      "My son is he disgraened: his son blot super.\n",
      "\n",
      "EDWARD:\n",
      "Nay, but, a walk, that son his suppose peer.\n",
      "\n",
      "RICHARD:\n",
      "'Twas thou high to tell his worth succeed woe.\n",
      "I had found thou but the books when kill'd sadly,\n",
      "Thank my son, as the ear mischange the other brothers:\n",
      "Succession, son as child I buried them have.\n",
      "\n",
      "RICHARD:\n",
      "A deep cose shall be in high.\n",
      "\n",
      "EDWARD:\n",
      "What should in sadness cross that here is a succeed.\n",
      "\n",
      "EDWARD:\n",
      "I know when I should so distress for one half?\n",
      "\n",
      "WARWICK:\n",
      "Once more, blow, proud my report son our house!\n",
      "\n",
      "RICHARD:\n",
      "And why should then I learn convete as king,\n",
      "What robb'd in this sons proceed pepherce,\n",
      "I perior thee to several sons thereof any thought,\n",
      "And begin in peniten\n",
      "1/10 -- 3007.64s \tTrain loss \t1.0019 \tEval loss \t0.8706 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "In derous captive to delay of your hate;\n",
      "For limit lay aside, you, and your party tales;\n",
      "And, if stay, swears, 'tis such like regolve.\n",
      "Young dry, else nobils and take you or either.\n",
      "\n",
      "GREMIO:\n",
      "When you are all?\n",
      "\n",
      "SEBASTIAN:\n",
      "I' fail traitor, I say.\n",
      "\n",
      "GONZALO:\n",
      "I say, thou'rt thou ne'er balely. Though must\n",
      "seest men.\n",
      "\n",
      "ANTONIO:\n",
      "I prother worse.\n",
      "\n",
      "GONZALO:\n",
      "Is it?\n",
      "\n",
      "ANTONIO:\n",
      "Thou seem stayed.\n",
      "\n",
      "Mastependenenant, for a lord.\n",
      "\n",
      "GONZALO:\n",
      "Prithee, good father.\n",
      "\n",
      "ANTONIO:\n",
      "Prithee, bring: capell us all.\n",
      "\n",
      "GONZALO:\n",
      "Sir, trusty, rully.\n",
      "\n",
      "SEBASTIAN:\n",
      "Sir, Lord Aufidius; a man's tush appear.\n",
      "\n",
      "ANTONIO:\n",
      "That's the woman.\n",
      "\n",
      "SEBASTIAN:\n",
      "A lord throu came.\n",
      "\n",
      "ADRIAN:\n",
      "Ay.\n",
      "\n",
      "ADRIAN:\n",
      "'Tis any thing at once, but, if our comfort,\n",
      "That thou hast not a devilish flat did to addle me,\n",
      "I'll fool myself; and diver your honourable well\n",
      "Of that I missinglys, and earnest give it\n",
      "Proceeded for such a spirit! What! dreams home? hoo! for 'tis a\n",
      "not appearel, as he hath any toes a blot; a toys\n",
      "conclusion is unpleasing.\n",
      "\n",
      "SEBASTIAN:\n",
      "a devil s\n",
      "2/10 -- 3069.11s \tTrain loss \t0.8905 \tEval loss \t0.7286 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "The man, almost of your own, how musterly, I come to Pompey.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Peters, good my friend, I come.\n",
      "\n",
      "GLOUCESTREMIO:\n",
      "My heart is taken.\n",
      "A gentleman portly to my jest of the feast:\n",
      "Peter will I beside me play'd.\n",
      "\n",
      "GREMIO:\n",
      "Tush me.\n",
      "\n",
      "BAPTISTA:\n",
      "But I, to do not meet as I to my knowledge:\n",
      "For me, to not by me, unless it, I'll to you.\n",
      "\n",
      "PETRUCHIO:\n",
      "Come, Was not as a misfortune merry as the me?\n",
      "It is nearer memory, to men of my house:\n",
      "And there's never so meet to meet me out.\n",
      "My daughter Kate, I am not tell thee a word:\n",
      "I hear me if yet to my tongue to my body,\n",
      "And yet my wife, I trust my mouth to myself.\n",
      "\n",
      "PETRUCHIO:\n",
      "Then villain, all these never affections\n",
      "Be extremes, wrought meet to love me in my pities,\n",
      "And I'll be impervice my mind.\n",
      "\n",
      "BAPTISTA:\n",
      "Be mock'd your good pale, my lord.\n",
      "\n",
      "GREMIO:\n",
      "Know, my dearer was is lay too late.\n",
      "\n",
      "KATHARINA:\n",
      "What! I beseech you, none more, to begin.\n",
      "\n",
      "BAPTISTA:\n",
      "What, not protector speaks that I meaner\n",
      "My lord, that is too much. You should for this,\n",
      "Be perf\n",
      "3/10 -- 3407.61s \tTrain loss \t0.8127 \tEval loss \t0.6516 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "Where is my dear? is the meat this?\n",
      "Who, sirrah, here be false we now? But come thy love.\n",
      "What, how far upon my weapon, coz, this\n",
      "triumph my south-trashesborne conceible arms,\n",
      "Thy brow peace away be rest! What canst thou not\n",
      "Looks call'd, sees he brought out. Do your tribunes\n",
      "A soul upon this?\n",
      "\n",
      "LERDINE:\n",
      "To save heads upon me, good lords;\n",
      "And be the fairest slanders King Hortensio the prince\n",
      "That Hereford's lovely Greck. Fie, fie, lords! Now, all mends\n",
      "As well as there is sea?\n",
      "Lords, to have heard the Small'd thrust throne!\n",
      "Whilst Signior Gremio?\n",
      "Kilt Cludio? No; no, my sripers!\n",
      "Where's Northumberland, there, there look'd the all.\n",
      "The bait the traitor maids? What, look thou this?\n",
      "Dost thou read?  thou poor millstys this slain?\n",
      "How now! who says thou commands that after,\n",
      "And not Gaunt hath made me 'pardon' still be\n",
      "And not professon, coping the world that would\n",
      "Cloves we patient their late thou such denying,\n",
      "Thou steal'dst it not; thou dost retermed\n",
      "Were shall remove the places of thy so\n",
      "4/10 -- 2920.74s \tTrain loss \t0.7489 \tEval loss \t0.5660 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "How here's report! a medly life behind!\n",
      "Long have I protest, like you the sea\n",
      "behind, to to tie to come. For ye till, sir, I am in\n",
      "more to constate: the being so much king's eye,\n",
      "that I might enrices be a long; I see would he\n",
      "must up. Tell him, like a fast of dew behold.\n",
      "\n",
      "First Servingman:\n",
      "Why, true! no; take up grief to you, he's wit to you:\n",
      "so you will not as he to him: cleathe him! Well, when, but\n",
      "apple. My straight will, he shall port you not\n",
      "for this oracle. See where have you to the heart.\n",
      "\n",
      "Second Servingman:\n",
      "Besides, you have consul.\n",
      "\n",
      "Third Servingman:\n",
      "What, do you need to here?\n",
      "\n",
      "First Servingman:\n",
      "Why, he that when we speaks to the war; where he has\n",
      "deserved wounds, he's dead; banish to see it not him.\n",
      "\n",
      "Third Servingman:\n",
      "O, I think he, of her.\n",
      "\n",
      "Second Servingman:\n",
      "Leave that we look here, I'll carry to come to you, sir.\n",
      "\n",
      "Third Servingman:\n",
      "We shall not remember me too.\n",
      "\n",
      "CORIOLANUS:\n",
      "Talk not to my good. Worse: the people\n",
      "Is shipble stars, shall behind the sights to seem\n",
      "In persons \n",
      "5/10 -- 2920.53s \tTrain loss \t0.7006 \tEval loss \t0.4822 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "Aged command to prison mine armour follows.\n",
      "But, brother, tell me thee to a mistress.\n",
      "\n",
      "ROMEO:\n",
      "O is my noble's prince, in sadness physic boot?\n",
      "\n",
      "BENVOLIO:\n",
      "I'll be his headstrous quarter'd for Mantua:\n",
      "With all the maid to hear it which time\n",
      "She is come to prove to might move me.\n",
      "\n",
      "ROMEO:\n",
      "Hour stern, is a dead; and, and I think it both,\n",
      "Thou she wouldst be made it; come with her.\n",
      "\n",
      "BENVOLIO:\n",
      "More is boot.\n",
      "\n",
      "ROMEO:\n",
      "Alas it may but stop my soldiers,\n",
      "My love's envying it will all tender\n",
      "To look upon the night's months.\n",
      "\n",
      "BENVOLIO:\n",
      "At poor is to see in Tibertio.\n",
      "\n",
      "ROMEO:\n",
      "Let me see think it stay all a while:\n",
      "Where is the world were very promise\n",
      "Behold and now the stone of our breams,\n",
      "Who as thou forgive my God, by the Lady Grey,\n",
      "And let us be brief his father's head.\n",
      "\n",
      "BUSHY:\n",
      "The palm is put upon this most is our and bother.\n",
      "\n",
      "BAGOT:\n",
      "I shall follow Peteux' cheeb hither spring,\n",
      "Am contempt to our frowning good people.\n",
      "\n",
      "BUCKINGHAM:\n",
      "So more is the senate, my lord is good\n",
      "For to their and issue Madam, Ca\n",
      "6/10 -- 3197.42s \tTrain loss \t0.6682 \tEval loss \t0.4598 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "honour to the field, did send him of need\n",
      "For celebried the rock\n",
      "Of that word chiden seem's love! that but that duke\n",
      "May suspect so far from within the depth of his world?\n",
      "What hast thou, the precious issued the deed\n",
      "In the king and Duke of York!\n",
      "Is not Richard that I say should from the Lord,\n",
      "As thou art to expect'st, thou lose pardon-\n",
      "When thou prate the danger of thy face,\n",
      "Arre the adventure of thy conceme she blood,\n",
      "Arise, fast of God's sake, speed and spring weeds,\n",
      "She says that never sent to the world tack,\n",
      "While he, arm dead, in life, she, of remember:\n",
      "This blood recover's violets that e'er I remain\n",
      "From the tenthence of these throne, sate thee!\n",
      "Now, the treason of thy words are flowers\n",
      "That heir crown fushly and lodgen so seems\n",
      "In that seem'd the fiments; that thou sure\n",
      "That the royal fix'd, the point of storm\n",
      "Is up so doing, such a condition\n",
      "Is goad a thought of ear, since that,\n",
      "Laled on summer beauty, 'Death, 'Death this meet\n",
      "In every garment, and thou say'st the woman\n",
      "Whom h\n",
      "7/10 -- 2883.18s \tTrain loss \t0.6462 \tEval loss \t0.4192 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "Thies, two austore, to say that I was.\n",
      "That tell the friar's womb I sleep out mine.\n",
      "\n",
      "Best Katharina Perdina, I say:\n",
      "Young farewell, good fortune hath I put\n",
      "you to a scourteen grown time her had pays;\n",
      "you think my advised at thy departure,\n",
      "Give me a day I on a dedition.\n",
      "Cousin, doth you know my depart my dear:\n",
      "If you do be savergised, I pleased to counterfight,\n",
      "and give my paitor's rascal, so out flies.\n",
      "To what the means to that make King Edward's wife?\n",
      "Son, Let Surrey, you that we shall be full:\n",
      "Long shall I still upon thee keep to the king,\n",
      "Which I with gently offended me to all.\n",
      "\n",
      "HASTINGS:\n",
      "How now, my Lord of Somerset, at Thus Christend;\n",
      "Shall be my vouch for then arm of death?\n",
      "Nay, no matter, the great confession this:\n",
      "The faith, and the season, and the sea, pathor;\n",
      "They are but this children bear death in you:\n",
      "And therefore, Tranio, for I go very enemy,\n",
      "Take too commend to you.'\n",
      "\n",
      "EXETER:\n",
      "My offer, my liege,\n",
      "How fares our countryment! I am the county:\n",
      "One Isabel, cousin, straight fi\n",
      "8/10 -- 2906.83s \tTrain loss \t0.6295 \tEval loss \t0.3910 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "I call these words, to give the grace of whose woe,\n",
      "Soon as he would have as despair want sparced.\n",
      "\n",
      "SIR STEPHEN SCROOP:\n",
      "Nay, I will rid the presumm'd can tell the state;\n",
      "For by thou art a fool into firm in heyp.\n",
      "\n",
      "DUKE OF YORK:\n",
      "Had he were recorded to me a world to die.\n",
      "\n",
      "DUKE OF YORK:\n",
      "It would never should be rejoice to rooming thee.\n",
      "\n",
      "BUCKINGHAM:\n",
      "I pray thee, gentle sight, my heart to my dear\n",
      "For given aid order times in true and wrapt\n",
      "Upon the gracious soul join'd that which I know.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "To fight indeed, my sorrow hath lost myself.\n",
      "\n",
      "RIVERS:\n",
      "My Lord of Gloucester\n",
      "Will you fight again against my slain Hastings,\n",
      "And left again to fear this pronounce may.\n",
      "O Buckingham now, be traitor to God,\n",
      "Nod sighs but a king and obsequious for tribune,\n",
      "But many yet a praud means to object sick with him,\n",
      "And make an ungreatiest your grave\n",
      "My gracious unliquities in your love\n",
      "Drogorders he shall Bianca know this is dagger,\n",
      "And yet sigh we have new but down in this,\n",
      "Perhaps to waken again.\n",
      "\n",
      "L\n",
      "9/10 -- 2920.91s \tTrain loss \t0.6163 \tEval loss \t0.3552 \n",
      "---------- Predict from empty input:\n",
      "\n",
      "She it for that, is no more; call thee to thy state:\n",
      "Doth was a soldier to heaven's full of flesh!\n",
      "For Edward, safely; and flowerest thou likest,\n",
      "Dult is thy and dead dead; and let thee feather:\n",
      "And thou mayst be disgraced purposed!\n",
      "I pray thee, let it stir; thee be hooty needs,\n",
      "Come, do any that can was well for so quit this:\n",
      "Plutage is coming homeon, he was elder wont\n",
      "To meet his son and wave's eleven years;\n",
      "His woman arms appearing old him:\n",
      "His wife and his obey'd his dovotion,\n",
      "Let's confirm'd! he was forced to cook my word:\n",
      "'Tis death to known 'tis deep he is widow;\n",
      "For thou canst not tender what thou speak'st!\n",
      "\n",
      "Lord Marshal:\n",
      "The forma stood with me on the side.\n",
      "\n",
      "Nurse:\n",
      "Romeo! they what?\n",
      "\n",
      "PETER:\n",
      "My wound the man is of catter, when I saw here\n",
      "Have fell in deserved the matter's death:\n",
      "He was worth had I desire thee, why I death\n",
      "Best well am fool't the yale; clet her to follower.\n",
      "\n",
      "PETRUCHIO:\n",
      "You'll forward sign of body.\n",
      "\n",
      "Nurse:\n",
      "This is the pate and the old fall's interch yet,\n",
      "if her s\n",
      "Training completed. Elapsed time: 2922.20s\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from learning.shakespeare_generator.model import Batch, ParallelBatchLearner\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "print(config)\n",
    "\n",
    "model = ShakespeareGenerator(\n",
    "    config=config,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "learner = ParallelBatchLearner(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=config.device,\n",
    ")\n",
    "print(learner)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=Batch.from_samples,\n",
    "    num_workers=4,  # Parallel data loading\n",
    "    pin_memory=True,  # Faster CPU->GPU transfer\n",
    "    persistent_workers=True,  # Keep workers alive between epochs\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    collate_fn=Batch.from_samples,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Starting training...\\n\"\n",
    "    f\"Expecting initial loss around {math.log(tokenizer.vocab_size)}\"\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = learner.train(train_dataloader, [])\n",
    "    eval_loss = learner.eval(val_dataloader, [])\n",
    "    print(\n",
    "        f\"{epoch}/{config.epochs} -- {time.time() - start_time:.2f}s \"\n",
    "        f\"\\tTrain loss \\t{train_loss:.4f} \"\n",
    "        f\"\\tEval loss \\t{eval_loss:.4f} \"\n",
    "    )\n",
    "\n",
    "    inputs = torch.ones((1, 1), dtype=torch.long, device=config.device)\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=1000,\n",
    "    )\n",
    "\n",
    "    print(\"---------- Predict from empty input:\")\n",
    "    for i in range(outputs.shape[0]):\n",
    "        print(tokenizer.i2t(outputs[i].tolist()))\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Training completed. Elapsed time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed7b2810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|pad|>': 0, '\\n': 1, ' ': 2, '!': 3, '$': 4, '&': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '3': 10, ':': 11, ';': 12, '?': 13, 'A': 14, 'B': 15, 'C': 16, 'D': 17, 'E': 18, 'F': 19, 'G': 20, 'H': 21, 'I': 22, 'J': 23, 'K': 24, 'L': 25, 'M': 26, 'N': 27, 'O': 28, 'P': 29, 'Q': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'W': 36, 'X': 37, 'Y': 38, 'Z': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n",
      "---------- Predict from empty input:\n",
      "\n",
      "GLOUCESTER:\n",
      "I thank thee, gentle Warwick, despited:\n",
      "And Natu, what this time we shall hear\n",
      "Shall be the friends to this foot offence?\n",
      "\n",
      "CLARENCE:\n",
      "Alas! fool! fly! I wondrous word!\n",
      "\n",
      "WARWICK:\n",
      "If Warwick with not your help of my foes,\n",
      "I have follow'd the time town.\n",
      "\n",
      "RICHARD:\n",
      "Trees out at add shrewd of gentle king,\n",
      "And so fortune's subjects to fight again.\n",
      "So did heaven a service I made.\n",
      "\n",
      "WARWICK:\n",
      "Never to was not for so quarrel and thou yet?\n",
      "\n",
      "KING EDWARD IV:\n",
      "The stronger concludes in our victory.\n",
      "\n",
      "GLOUCESTER:\n",
      "Not a word: I wild swear out a word duty is consent.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Unless Buckingbroke of woman that beneath:\n",
      "Where is thy friend, even with smeet have woe!\n",
      "\n",
      "CLIFFORD:\n",
      "My lord, thy father's death thou here is the world,\n",
      "Thou shalt have but warrw thee was dews sting;\n",
      "But thy best her brothers to hurl scoldiers;\n",
      "Which thou decreep'st, false deeds and the queen,\n",
      "During that he his deeds thirty seeing thee Tybalt?\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Yes, I accessed be thee on thy duty;\n",
      "And therefore be ne\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.token_to_index)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# shape: [2, 1] -- (B=2, S=1)\n",
    "inputs = torch.ones((1, 1), dtype=torch.long, device=config.device)\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_length=1000,\n",
    ")\n",
    "\n",
    "print(\"---------- Predict from empty input:\")\n",
    "for i in range(outputs.shape[0]):\n",
    "    print(tokenizer.i2t(outputs[i].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/shakespeare_generator.pt\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"../models/shakespeare_generator.pt\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../models/shakespeare_generator.pt\n",
      "ShakespeareGenerator(\n",
      "  (embedding): Embedding(66, 256)\n",
      "  (positional_embedding): Embedding(512, 256)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (heads): MultiHeadAttention(\n",
      "        (qkv_fc): Linear(in_features=256, out_features=768, bias=True)\n",
      "        (projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (feed_forward): FeedForward(\n",
      "        (linear): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=256, out_features=66, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model_load_path = \"../models/shakespeare_generator.pt\"\n",
    "model2 = ShakespeareGenerator(\n",
    "    config=config,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "model2.load_state_dict(torch.load(model_load_path, map_location=config.device))\n",
    "model2.to(config.device)\n",
    "model2.eval()\n",
    "print(f\"Model loaded from {model_load_path}\")\n",
    "\n",
    "print(model2)\n",
    "\n",
    "outputs = model2.generate(\n",
    "    inputs,\n",
    "    max_length=1000,\n",
    ")\n",
    "\n",
    "print(\"---------- Predict from empty input:\")\n",
    "for i in range(outputs.shape[0]):\n",
    "    print(tokenizer.i2t(outputs[i].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
